{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Letter count (Sent Avg)', 'Letter count (Sent SD)', 'Letter count (Sent Max)', 'Letter count (Sent Min)', 'Word count (Doc)', 'Word count (Sent Avg)', 'Word count (Sent SD)', 'Word count (Sent Max)', 'Word count (Sent Min)', 'Type count (Doc)', 'Type count (Sent Avg)', 'Type count (Sent SD)', 'Type count (Sent Max)', 'Type count (Sent Min)', 'Sentence count (Doc)']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with the correct encoding and specify headers\n",
    "file_path = 'texts_2024_1120_aggregate.csv'\n",
    "\n",
    "# Define the headers\n",
    "headers = ['fullname', 'Measures', 'Amount', 'Level', 'Function']  # Replace with your actual headers\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='latin1', names=headers, header=0)\n",
    "df['filename'] = df['fullname'].str.split('/').str[-1]\n",
    "\n",
    "# Extract type, id, and model\n",
    "df[['type', 'id', 'model']] = df['filename'].str.extract(r'(\\w+)_(\\d+)@(\\w+)')\n",
    "#measures_to_compare = unique[1::5][:50]\n",
    "filtered_measures = [measure for measure in df['Measures'] if ('(par' or '-par') not in measure]\n",
    "print(filtered_measures[:15])\n",
    "# Prepare DataFrames for comparison\n",
    "df = df[df['Measures'].isin(filtered_measures)]\n",
    "grouped2 = df.groupby(['type', 'model', 'Measures'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measures    id    model  type  Adjective avg position (Doc)  \\\n",
      "0         0007     Meta  acad                      0.496633   \n",
      "1         0007     Meta   fic                      0.526100   \n",
      "2         0007  chunk_1  acad                      0.350858   \n",
      "3         0007  chunk_1   fic                      0.536830   \n",
      "4         0007  chunk_2  acad                      0.373590   \n",
      "5         0007  chunk_2   fic                      0.533355   \n",
      "\n",
      "Measures  Adjective avg position (Sent Avg)  \\\n",
      "0                                  0.375528   \n",
      "1                                  0.311252   \n",
      "2                                  0.305196   \n",
      "3                                  0.396934   \n",
      "4                                  0.426357   \n",
      "5                                  0.473503   \n",
      "\n",
      "Measures  Adjective avg position (Sent Max)  \\\n",
      "0                                  0.833333   \n",
      "1                                  1.000000   \n",
      "2                                  0.892857   \n",
      "3                                  0.677966   \n",
      "4                                  0.857143   \n",
      "5                                  1.000000   \n",
      "\n",
      "Measures  Adjective avg position (Sent Min)  Adjective avg position (Sent SD)  \\\n",
      "0                                       0.0                          0.367213   \n",
      "1                                       0.0                          0.316207   \n",
      "2                                       0.0                          0.258629   \n",
      "3                                       0.0                          0.217696   \n",
      "4                                       0.0                          0.247377   \n",
      "5                                       0.0                          0.370976   \n",
      "\n",
      "Measures  Adjective burstiness (Doc)  Adjective concentration (Doc)  ...  \\\n",
      "0                           0.281979                       0.333333  ...   \n",
      "1                          -0.164285                       0.160000  ...   \n",
      "2                           0.150045                      -0.437500  ...   \n",
      "3                           0.033349                       0.130435  ...   \n",
      "4                          -0.033526                      -0.255814  ...   \n",
      "5                           0.056082                       0.000000  ...   \n",
      "\n",
      "Measures  Word-lemma Levenshtein dist. (Sent Max)  \\\n",
      "0                                        0.846154   \n",
      "1                                        1.000000   \n",
      "2                                        0.666667   \n",
      "3                                        2.000000   \n",
      "4                                        1.000000   \n",
      "5                                        0.750000   \n",
      "\n",
      "Measures  Word-lemma Levenshtein dist. (Sent Min)  \\\n",
      "0                                        0.090909   \n",
      "1                                        0.000000   \n",
      "2                                        0.076923   \n",
      "3                                        0.000000   \n",
      "4                                        0.074074   \n",
      "5                                        0.000000   \n",
      "\n",
      "Measures  Word-lemma Levenshtein dist. (Sent SD)  Zipf frequency (Doc)  \\\n",
      "0                                       0.262115              5.179899   \n",
      "1                                       0.289840              5.933817   \n",
      "2                                       0.153418              4.774171   \n",
      "3                                       0.554477              5.817307   \n",
      "4                                       0.224219              4.738007   \n",
      "5                                       0.186465              5.362816   \n",
      "\n",
      "Measures  Zipf frequency (Sent Avg)  Zipf frequency (Sent Max)  \\\n",
      "0                          5.091030                   5.735615   \n",
      "1                          5.911963                   6.568567   \n",
      "2                          4.872449                   5.850451   \n",
      "3                          5.035930                   6.063014   \n",
      "4                          4.882725                   5.655644   \n",
      "5                          4.906517                   5.942733   \n",
      "\n",
      "Measures  Zipf frequency (Sent Min)  Zipf frequency (Sent SD)  \\\n",
      "0                          3.792984                  0.632075   \n",
      "1                          4.424436                  0.453090   \n",
      "2                          3.076336                  0.666984   \n",
      "3                          0.000000                  1.807155   \n",
      "4                          3.304451                  0.658912   \n",
      "5                          1.547505                  1.464176   \n",
      "\n",
      "Measures  Zipf goodness of fit (Doc)  Zipf steepness of curve (Doc)  \n",
      "0                           0.950318                       0.503050  \n",
      "1                           0.879783                       0.686809  \n",
      "2                           0.950671                       0.667765  \n",
      "3                           0.925349                       0.733885  \n",
      "4                           0.944203                       0.652330  \n",
      "5                           0.944089                       0.642532  \n",
      "\n",
      "[6 rows x 1781 columns]\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.pivot(index=['id', 'model', 'type'], columns='Measures', values='Amount').reset_index()\n",
    "print(pivot_df[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             fullname  \\\n",
      "4   texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "5   texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "6   texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "7   texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "8   texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "13  texts_2024_1120_results/chunk_1_acad/acad_0007...   \n",
      "\n",
      "                   Measures      Amount     Level Function  type    id  \\\n",
      "4   Letter count (Sent Avg)  170.687500  sentence  average  acad  0007   \n",
      "5    Letter count (Sent SD)   66.316131  sentence    stdev  acad  0007   \n",
      "6   Letter count (Sent Max)  323.000000  sentence  maximum  acad  0007   \n",
      "7   Letter count (Sent Min)   85.000000  sentence  minimum  acad  0007   \n",
      "8          Word count (Doc)  509.000000  document      NaN  acad  0007   \n",
      "13    Word count (Sent Avg)   31.812500  sentence  average  acad  0007   \n",
      "\n",
      "      model  \n",
      "4   chunk_1  \n",
      "5   chunk_1  \n",
      "6   chunk_1  \n",
      "7   chunk_1  \n",
      "8   chunk_1  \n",
      "13  chunk_1  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'texts_2024_1120_results/chunk_1_acad/acad_0007@chunk_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m corri \u001b[38;5;241m=\u001b[39m corri\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(corri[:\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcorri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m high_corr \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m correlation_matrix \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(correlation_matrix[col] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Remove highly correlated features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20191882\\Anaconda\\envs\\Work\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\20191882\\Anaconda\\envs\\Work\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\20191882\\Anaconda\\envs\\Work\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\20191882\\Anaconda\\envs\\Work\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'texts_2024_1120_results/chunk_1_acad/acad_0007@chunk_1.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "outcomes = df['model']\n",
    "# Correlation-based filtering\n",
    "corri = df.copy()\n",
    "corri = corri.drop(columns=['model', 'id', 'type', 'fullname', 'Level', 'Function', 'filename'])\n",
    "print(corri[:6])\n",
    "correlation_matrix = corri.corr()\n",
    "high_corr = [col for col in correlation_matrix if any(correlation_matrix[col] > 0.9)]\n",
    "\n",
    "# Remove highly correlated features\n",
    "data_filtered = df.drop(columns=high_corr)\n",
    "\n",
    "# ANOVA Test for feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=100)  # Select top 100 features\n",
    "selected_features = selector.fit_transform(data_filtered, outcomes)\n",
    "\n",
    "# Model-based feature selection\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=100)\n",
    "rfe_features = rfe.fit_transform(data_filtered, outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Meta       0.91      0.77      0.83        13\n",
      "     chunk_1       0.36      0.44      0.40         9\n",
      "     chunk_2       0.45      0.45      0.45        11\n",
      "         gpt       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.68      0.67      0.67        40\n",
      "weighted avg       0.68      0.65      0.66        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "X = pivot_df.drop(columns=['model'])\n",
    "y = pivot_df['model']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Word count (Doc)', 'Type count (Doc)', 'Sentence count (Doc)', 'Paragraph count (Doc)', 'Hapax legomena count (Doc)', 'Hapax legomena incidence (Doc)', 'Adjective count (Doc)', 'Adverb count (Doc)', 'Interjection count (Doc)', 'Lexical verb count (Doc)', 'Noun count (Doc)', 'Proper noun count (Doc)', 'Lexical item count (Doc)', 'Adposition count (Doc)', 'Auxiliary count (Doc)']\n",
      "type  model  Measures                         \n",
      "acad  Meta   Adjective avg position (Doc)         0.490135\n",
      "             Adjective avg position (Sent Avg)    0.392278\n",
      "             Adjective avg position (Sent Max)    0.819249\n",
      "             Adjective avg position (Sent Min)    0.048171\n",
      "             Adjective avg position (Sent SD)     0.254250\n",
      "                                                    ...   \n",
      "      gpt    Zipf frequency (Sent Max)            5.464279\n",
      "             Zipf frequency (Sent Min)            4.071200\n",
      "             Zipf frequency (Sent SD)             0.379062\n",
      "             Zipf goodness of fit (Doc)           0.944001\n",
      "             Zipf steepness of curve (Doc)        0.650257\n",
      "Name: Amount, Length: 7112, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "filtered_measures2 = [measure for measure in df['Measures'] if '(Doc)' in measure]\n",
    "df = df[df['type'] == 'acad']\n",
    "print(filtered_measures2[:15])\n",
    "dfDoc = df[df['Measures'].isin(filtered_measures2)]\n",
    "grouped2 = df.groupby(['type', 'model', 'Measures'])\n",
    "\n",
    "# Calculate the mean for each feature in the group\n",
    "mean_features2 = grouped2['Amount'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(mean_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  model  Measures                         \n",
      "acad  Meta   Adjective avg position (Doc)         0.490135\n",
      "             Adjective avg position (Sent Avg)    0.392278\n",
      "             Adjective avg position (Sent Max)    0.819249\n",
      "             Adjective avg position (Sent Min)    0.048171\n",
      "             Adjective avg position (Sent SD)     0.254250\n",
      "                                                    ...   \n",
      "fic   gpt    Zipf frequency (Sent Max)            6.061212\n",
      "             Zipf frequency (Sent Min)            4.094123\n",
      "             Zipf frequency (Sent SD)             0.444964\n",
      "             Zipf goodness of fit (Doc)           0.945431\n",
      "             Zipf steepness of curve (Doc)        0.677113\n",
      "Name: Amount, Length: 14224, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(['type', 'model', 'Measures'])\n",
    "\n",
    "# Calculate the mean for each feature in the group\n",
    "mean_features = grouped['Amount'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(mean_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrameGroupBy' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrouped\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrameGroupBy' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Filter data for chunk_1 and other models\n",
    "chunk_1_data = df[mean_features['model'] == 'chunk_1']\n",
    "other_models_data = df[df['model'] != 'chunk_1']\n",
    "\n",
    "# Merge the data on 'type' and 'Measures'\n",
    "merged_data = pd.merge(chunk_1_data, other_models_data, on=['type', 'Measures'], suffixes=('_chunk_1', '_other'))\n",
    "\n",
    "# Calculate the difference\n",
    "merged_data['Difference'] = merged_data['Amount_chunk_1'] - merged_data['Amount_other']\n",
    "\n",
    "# Plot the differences\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=merged_data, x='Measures', y='Difference', hue='type')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Differences in Measures between chunk_1 and Other Models')\n",
    "plt.xlabel('Measures')\n",
    "plt.ylabel('Difference')\n",
    "plt.legend(title='Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
